{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for sentiment analysis metrics visualization\n",
        "metrics = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
        "scores = [0.43, 0.42, 0.42, 0.76]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color='salmon')\n",
        "plt.ylim(0, 1.1)\n",
        "plt.title('Sentiment Analysis Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Save the figure\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "H0L6WX0K8uLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load your real Word2Vec model\n",
        "w2v_model = KeyedVectors.load_word2vec_format(\"/content/w2v.bin\", binary=True)\n",
        "\n",
        "# 2) Embedding utility\n",
        "def get_embedding(text):\n",
        "    tokens = text.lower().split()\n",
        "    valid_tokens = [t for t in tokens if t in w2v_model]\n",
        "    if not valid_tokens:\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "    return np.mean([w2v_model[t] for t in valid_tokens], axis=0)\n",
        "\n",
        "# 3) Your evaluation data (replace with your actual retrievals/relevants)\n",
        "evaluation_data = [\n",
        "    {\n",
        "        \"query\": \"What is the soul?\",\n",
        "        \"top_k\": {\n",
        "            \"BG2.12\": \"Never was there a time when I did not exist...\",\n",
        "            \"BG2.47\": \"You have a right to perform your duty...\",\n",
        "            \"BG3.16\": \"He who does not follow the cycle of sacrifice...\"\n",
        "        },\n",
        "        \"relevant\": {\"BG2.12\"}\n",
        "    },\n",
        "    # … add your other queries here …\n",
        "]\n",
        "\n",
        "# 4) Compute reranked metrics\n",
        "all_prec, all_rec, all_f1, all_acc = [], [], [], []\n",
        "\n",
        "for item in evaluation_data:\n",
        "    q_vec = get_embedding(item[\"query\"])\n",
        "    ids = list(item[\"top_k\"].keys())\n",
        "    vecs = np.vstack([get_embedding(text) for text in item[\"top_k\"].values()])\n",
        "\n",
        "    sim = cosine_similarity(q_vec.reshape(1, -1), vecs)[0]\n",
        "    rerank = [ids[i] for i in np.argsort(sim)[::-1]]\n",
        "    predicted = set(rerank[:len(ids)])\n",
        "\n",
        "    relevant = item[\"relevant\"]\n",
        "    universe = list(relevant.union(predicted))\n",
        "    y_true = [1 if u in relevant else 0 for u in universe]\n",
        "    y_pred = [1 if u in predicted else 0 for u in universe]\n",
        "\n",
        "    all_prec.append(precision_score(y_true, y_pred))\n",
        "    all_rec.append(recall_score(y_true, y_pred))\n",
        "    all_f1.append(f1_score(y_true, y_pred))\n",
        "    all_acc.append(accuracy_score(y_true, y_pred))\n",
        "\n",
        "# 5) Average and display\n",
        "df_metrics_reranked = pd.DataFrame({\n",
        "    \"Metric\": [\"Precision\", \"Recall\", \"F1 Score\", \"Accuracy\"],\n",
        "    \"Score\": [\n",
        "        np.mean(all_prec),\n",
        "        np.mean(all_rec),\n",
        "        np.mean(all_f1),\n",
        "        np.mean(all_acc)\n",
        "    ]\n",
        "})\n",
        "display(df_metrics_reranked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "z_AiawM6WkKy",
        "outputId": "2ed84320-cc07-415e-edb7-c74251a36414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-593f2e54994e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}
